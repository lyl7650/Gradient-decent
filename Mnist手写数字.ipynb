{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "40834193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "a6ac70cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set=torchvision.datasets.MNIST(root='./data',\n",
    "                                     train=True,\n",
    "                                     download=False,\n",
    "                                     transform=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "29b71116",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set=torchvision.datasets.MNIST(root='./data',\n",
    "                                    transform=torchvision.transforms.ToTensor(),\n",
    "                                    download=False,\n",
    "                                    train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "2d0417c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([   #将输入的图片进行“[]”中的一系列的处理\n",
    "    transforms.ToTensor(),         #将输入图片进行转成3通道的张量，并将像素值压缩到0-1 \n",
    "    transforms.Normalize((0.1307,),(0.3081,))  # 这两个值使均值和方差,将图像数据进行标准化\n",
    "                                               #（这里使数据形成正态分布）\n",
    "]\n",
    ")\n",
    "batch_size=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "d395329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader=DataLoader(train_set,batch_size=batch_size, shuffle=True,num_workers=0)\n",
    "test_dataloader=DataLoader(test_set,batch_size=batch_size,shuffle=True,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df622a5",
   "metadata": {},
   "source": [
    "## 搭建网络，模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "338ac401",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=16,    # n_filters\n",
    "                kernel_size=5,      # filter size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=2,          # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n",
    "                ),                  # output shape (16, 28, 28)\n",
    "            nn.ReLU(),              # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     # output shape (32, 14, 14)\n",
    "            nn.ReLU(),                      # activation \n",
    "            nn.MaxPool2d(2),                # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)            # 展平多维的卷积图成 (batch_size, 32 * 7 * 7)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "10688b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "5d5a22ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++第1轮训练++++\n",
      "loss: 0.034036751836538315\n",
      "loss: 0.10468880747803842\n",
      "loss: 0.0943584059322576\n",
      "loss: 0.09222525307257064\n",
      "loss: 0.08814896368841814\n",
      "loss: 0.08277153241690804\n",
      "loss: 0.07964189589825853\n",
      "loss: 0.0795858176105023\n",
      "loss: 0.07747923125589863\n",
      "loss: 0.07572384189554146\n",
      "loss: 0.07412676711866867\n",
      "loss: 0.07131481050443399\n",
      "loss: 0.06955558339409776\n",
      "loss: 0.06759861760855175\n",
      "loss: 0.06670221177130967\n",
      "loss: 0.06613573548899923\n",
      "loss: 0.06507879180144087\n",
      "train loss0.0647, train accuracy58796.0/60000.0 (0.9799)\n",
      "+++++++第2轮训练++++\n",
      "loss: 0.012058623135089874\n",
      "loss: 0.03415434030962251\n",
      "loss: 0.03187426500474198\n",
      "loss: 0.03661498846658218\n",
      "loss: 0.037411481576938535\n",
      "loss: 0.03647618953139637\n",
      "loss: 0.03572638172251256\n",
      "loss: 0.037468621352681586\n",
      "loss: 0.03758775558007896\n",
      "loss: 0.037450450938337765\n",
      "loss: 0.037910165207493705\n",
      "loss: 0.03807287186924797\n",
      "loss: 0.037883391338761674\n",
      "loss: 0.03716896984554072\n",
      "loss: 0.03717418113791107\n",
      "loss: 0.038106647019900075\n",
      "loss: 0.0377742952826942\n",
      "train loss0.0373, train accuracy59265.0/60000.0 (0.9878)\n"
     ]
    }
   ],
   "source": [
    "def train_model():\n",
    "    cnn.train()\n",
    "    train_loss_all=[];train_acc_all=[]\n",
    "    for epoch in range(2):\n",
    "        print(\"+++++++第{}轮训练++++\".format(epoch+1))\n",
    "        train_loss=0.0;train_correct=0.0;train_num=0.0;train_accuracy=0.0\n",
    "        for step, data in enumerate(train_dataloader):\n",
    "            img,label=data\n",
    "            output=cnn(img)\n",
    "            loss = loss_func(output,label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "            ###计算损失，预测正确数量，准确率\n",
    "            train_correct+=(output.argmax(1)==label).sum().item()##第i轮预测正确数量\n",
    "            train_loss+=(loss.item()*img.size(0))   ##第i轮损失值\n",
    "            train_num+=img.size(0)\n",
    "            if step%300==0:\n",
    "                print(\"loss:\",train_loss/train_num)\n",
    "\n",
    "        train_loss_all.append(train_loss/train_num)\n",
    "        train_acc_all.append(train_correct/train_num)\n",
    "        print(\"train loss{:.4f}, train accuracy{}/{} ({:.4f})\".format(train_loss_all[-1],train_correct,train_num,\n",
    "                                                                      train_acc_all[-1]))\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "11332f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++++++第1轮评估++++\n",
      "val loss0.00048447493463754654\n",
      "val loss0.035059050744985595\n",
      "val loss0.028841819254027956\n",
      "val loss0.028369459748891088\n",
      "val loss0.028602542346601416\n",
      "val loss is:0.0279, val accuracy is:9911/10000 99.1100%\n",
      "+++++++第2轮评估++++\n",
      "val loss0.002067637164145708\n",
      "val loss0.00867289263656808\n",
      "val loss0.01025436863539399\n",
      "val loss0.009862066880653995\n",
      "val loss0.010363350169286604\n",
      "val loss is:0.0103, val accuracy is:9961/10000 99.6100%\n"
     ]
    }
   ],
   "source": [
    "def val_model():\n",
    "    cnn.eval()\n",
    "    test_loss_all=[];test_acc_all=[]\n",
    "    for epoch in range(2):\n",
    "        print(\"+++++++第{}轮评估++++\".format(epoch+1))\n",
    "        val_loss=0;val_correct=0;val_num=0;val_accuracy=0\n",
    "        for step,data in enumerate(test_dataloader):\n",
    "            img,label=data\n",
    "            output=cnn(img)\n",
    "            loss = loss_func(output,label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #计算损失，准确率\n",
    "            val_loss+=loss.item()*img.size(0)\n",
    "            val_correct+=(output.argmax(1)==label).sum().item()\n",
    "            val_num+=img.size(0)\n",
    "            if step%200==0:\n",
    "                print(\"val loss{}\".format(val_loss/val_num))\n",
    "        test_loss_all.append(val_loss/val_num)\n",
    "        test_acc_all.append(val_correct/val_num)\n",
    "        print(\"val loss is:{:.4f}, val accuracy is:{}/{} {:.4f}%\".format(test_loss_all[-1],val_correct,\n",
    "                                                                 val_num,100*test_acc_all[-1]))\n",
    "val_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

